{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: CNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs for Denoising\n",
    "\n",
    "1. Unet with residual skip connections\n",
    "2. Writing our own loss function\n",
    "\n",
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the dataset (already splitted into train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image preprocessing\n",
    "NB_IMAGES_TO_USE = 1000\n",
    "\n",
    "train_images = train_images[:NB_IMAGES_TO_USE] / 255.0\n",
    "test_images = test_images[:NB_IMAGES_TO_USE]  / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images with random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.subplot(121)\n",
    "pl.imshow(train_images[0], cmap=pl.cm.gray) \n",
    "pl.xticks(())\n",
    "pl.yticks(())\n",
    "pl.title(\"Original\")\n",
    "pl.subplot(122)\n",
    "pl.imshow(train_images[0] + np.random.normal(0., 0.1, (28, 28)), cmap=pl.cm.gray)\n",
    "pl.xticks(())\n",
    "pl.yticks(())\n",
    "pl.title(\"Noised (Input to the network)\")\n",
    "#pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(images):\n",
    "    while True:\n",
    "        for im in images:\n",
    "            noised = im + np.random.normal(0., 0.1, im.shape)\n",
    "            noised = noised[np.newaxis]\n",
    "            yield noised, im[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(train_gen)\n",
    "a, b = next(train_gen)\n",
    "print(\"Input shape\", a.shape)\n",
    "print(\"Output shape\", b.shape)\n",
    "pl.imshow(np.squeeze(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Residual Unit and Example\n",
    "\n",
    "<img src=\"images/residulal_unit_and_exple.png\" width=\"70%\" height=\"30%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Previous UNet with Residual Skip Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/unet_residual_skips.png\" width=\"70%\" height=\"30%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding: UNet with Residual Skip Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder part\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Conv2D(8, (3,3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "l1 = tf.keras.layers.Conv2D(8, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\", strides=2)(l1) \n",
    "l2 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\", strides=2)(l2) \n",
    "x = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "# Decoder part\n",
    "x = tf.keras.layers.Conv2DTranspose(16, (3,3), activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "\n",
    "x = tf.keras.layers.Add()([x, l2])\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(8, (3,3), activation=\"relu\", padding=\"same\", strides=2)(x)\n",
    "\n",
    "x = tf.keras.layers.Add()([x, l1])\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "# Output Layer\n",
    "x = tf.keras.layers.Conv2D(1, (3,3), activation=\"sigmoid\", padding=\"same\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce(gt, pred):\n",
    "    return -  gt * tf.math.log(pred) - (tf.ones_like(gt) - gt)*  tf.math.log(tf.ones_like(pred) - pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model and compile with the custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs, x) \n",
    "model.compile(loss=bce, optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a folder to store the training data for monitoring\n",
    "logdir = os.path.join(\"resnet_logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# give the previous folder to Tensorboard \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "train_gen = generator(train_images[:,:,:,np.newaxis])\n",
    "model.fit(train_gen, epochs=10, steps_per_epoch=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = test_images[5][np.newaxis, :,:, np.newaxis] + np.random.normal(0., 0.1, (1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(test_im, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model(test_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the loss on the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ground-truth is the actual image\n",
    "gt  = test_images[5][np.newaxis, :,:, np.newaxis].astype(np.float32) \n",
    "# computing the custom binary cross-entropy loss\n",
    "l = tf.reduce_mean(bce(gt, outputs))\n",
    "l.numpy() #unet - 0.037616905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.subplot(121)\n",
    "pl.imshow(np.squeeze(test_im))\n",
    "pl.subplot(122)\n",
    "pl.imshow(np.squeeze(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going further\n",
    "1. Study the robustness by tweaking the noise\n",
    "2. Add more layers \n",
    " - Increase the layers on each levels\n",
    " - **Add residual connections between layers of the same levels**\n",
    " - Increase the levels 3-4-5\n",
    "3. Try on other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
